# -*- coding: utf-8 -*-
"""AI_Fitness_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oz5JZhT37MWkpWABcCLaae9Azpn1eG4K
"""

# Install libraries for Website (Streamlit), AI (Transformers), and Graphs (Seaborn)
# !pip install streamlit pandas scikit-learn transformers torch matplotlib seaborn pyngrok -q

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from transformers import pipeline

# Load the dataset
try:
    df = pd.read_csv("megaGymDataset.csv")
    print("‚úÖ Success: Dataset loaded!")
    print(f"Total Rows: {len(df)}")
except FileNotFoundError:
    print("‚ùå Error: Please upload 'megaGymDataset.csv' to the Colab files.")

# 1. Show raw data (Top 5 rows)
print("--- RAW DATA PREVIEW ---")
display(df.head())

# 2. Check for missing values
null_count = df.isnull().sum().sum()
print(f"\nTotal Null Values Before Cleaning: {null_count}")

# 3. Clean the data (Drop rows with missing values)
if null_count > 0:
    df.dropna(inplace=True)
    print(f"‚úÖ Removed {null_count} empty values. Data is clean.")
else:
    print("‚úÖ Data is already clean.")

# 4. Verify cleaning
print(f"Total Null Values After Cleaning: {df.isnull().sum().sum()}")

# Set visual style
sns.set(style="whitegrid")

# Create a Bar Chart: Distribution of Exercises by Body Part
plt.figure(figsize=(10, 6))
# Count top 10 body parts
top_body_parts = df['BodyPart'].value_counts().index[:10]
sns.countplot(y='BodyPart', data=df, order=top_body_parts, palette='viridis')

plt.title('Top 10 Target Body Parts in Dataset', fontsize=16)
plt.xlabel('Number of Exercises', fontsize=12)
plt.ylabel('Body Part', fontsize=12)
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# from transformers import pipeline
# 
# # --- SETUP ---
# st.set_page_config(page_title="AI Fitness", page_icon="üí™", layout="wide")
# 
# @st.cache_data
# def load_data():
#     try:
#         df = pd.read_csv("megaGymDataset.csv")
#         df.dropna(inplace=True)
#         return df
#     except:
#         return None
# 
# @st.cache_resource
# def load_model():
#     return pipeline('text-generation', model='distilgpt2')
# 
# df = load_data()
# ai_generator = load_model()
# 
# # --- UI ---
# st.title("üí™ AI-Powered Personal Fitness Planner")
# st.markdown("### Project: Kaggle Data Analysis + Hugging Face AI")
# 
# # --- DATA REPORT ---
# with st.expander("üìä View Data Analysis Report", expanded=True):
#     if df is not None:
#         col1, col2 = st.columns([1, 1]) # Equal width columns
#         with col1:
#             st.write("**Cleaned Data (First 15 Rows):**")
#             # CHANGED: Now showing 15 rows
#             st.dataframe(df.head(15), height=400)
#         with col2:
#             st.write("**Top 7 Body Parts Distribution:**")
#             # CHANGED: Now showing Top 7 and slightly taller graph
#             fig, ax = plt.subplots(figsize=(6, 5))
#             sns.countplot(y='BodyPart', data=df, order=df['BodyPart'].value_counts().index[:7], ax=ax, palette='magma')
#             st.pyplot(fig)
# 
# st.markdown("---")
# 
# # --- AI APP ---
# st.header("ü§ñ Your Personal AI Coach")
# goal = st.sidebar.selectbox("Goal", ["Muscle Gain", "Weight Loss", "Strength"])
# target_part = st.sidebar.selectbox("Target Muscle", df['BodyPart'].unique())
# 
# col1, col2 = st.columns(2)
# with col1:
#     st.subheader(f"Exercises for {target_part}")
# 
#     # Filter Logic with Error Handling
#     filtered_data = df[df['BodyPart'] == target_part]
#     count = len(filtered_data)
# 
#     if count > 0:
#         sample_size = min(5, count)
#         st.table(filtered_data.sample(sample_size)[['Title', 'Type', 'Equipment']])
#     else:
#         st.warning(f"No exercises found for {target_part}!")
# 
# with col2:
#     st.subheader("üß† AI Motivation")
#     if st.button("Get AI Advice"):
#         with st.spinner("AI is thinking..."):
#             prompt = f"To achieve {goal}, the most important mindset is"
#             res = ai_generator(prompt, max_length=40, num_return_sequences=1)
#             st.success(f"'{res[0]['generated_text']}'")

import pandas as pd

# Replace 'Your_File_Path_Here.csv' with the actual path to your CSV file in Google Drive
try:
    df_from_drive = pd.read_csv('/content/megaGymDataset.csv')
    print('‚úÖ Success: Dataset loaded from Google Drive!')
    display(df_from_drive.head())
except FileNotFoundError:
    print('‚ùå Error: File not found. Please ensure the path is correct and the file exists.')
except Exception as e:
    print(f'An error occurred: {e}')

from pyngrok import ngrok

# 1. AUTHENTICATE
# REPLACE THE TEXT BELOW WITH YOUR ACTUAL TOKEN FROM NGROK DASHBOARD
ngrok.set_auth_token("YOUR ACTUAL TOKEN")

# 2. START TUNNEL
public_url = ngrok.connect(8501).public_url
print(f"üöÄ CLICK THIS LINK: {public_url}")

# 3. RUN APP
!streamlit run app.py
